
# Pattern Recognition
https://www.youtube.com/watch?v=TcoEApoadg8&t=307s

This note is credited largely to material organized by [[Paul Merritt]].


## Template Matching Theory
In this model, there is a unique template for anything that can be recognized. This is analogous to a large hashmap with sense data as keys, and labels as values.

Weaknesses:
***- This doesn't explain how sense data is filtered to form keys.***
***- Doesn't explain how new input -> label pairs are inserted.***
- Doesn't explain pattern variation: How can the same object map to the same label, even when details change? It seems that this model would require a different template for each orientation. Consider the letter "A", written with different fonts and styles.
- Doesn't explain variations in pattern orientation.
- Doesn't explain "Gestalt Phenomenon". These are situations where we infer patterns when they are only implied.
- Requires an enormous amount of templates.

## Feature Detection Theories
In this model, we identify **defining features** and their **combinations**, and recognize objects as a **set** of features. We say that this process is accomplished by **analysis by synthesis** where we extract features from a **sensory register**, which is a short-term storage location. These extracted features are matched with features in long term memory.

This class of model predicts **perceptual confusions**, where sets with a large number of common features will be mistaken for each other. This was shown by an experiment by [[Ulrif Niesser]]. This can effect distinguishing of identical twins, cars witht he same model and different years.

Weaknesses (also applies to Template Theory):
- Doesn't seem to explain how we recognize features. Is there a key-value map for features? Wouldn't this suffer from the same criticisms as Template theory?
- Doesn't account for bi-directional images, where the same image can be labeled in multiple ways. ***Many bi-directional images seem to involve confusion around the direction of converging corners in 3D space. They are confusions about depth.***
- Doesn't explain which features are the defining ones.
- Doesn't explain **context effects**, such as word-superiority, where subjects are better at identifying letters when they're included in a word that they recognize.


## Bottom-Up vs. Top-Down Processing
Both Template and Feature theories involve bottom-up (data-driven) processing only. 

**Bottom-Up** processing depends on basic elemental units, which are used as building blocks to compose larger objects.

**Top-Down** processing involves the use of global knowledge to detect patterns. Processing is based on higher level information such as meaningful context, observer knowledge, experience, bias, emotive state. ***How does this relate vertical cross-sections in the Straticarticulus? Higher level lenses apply filtering.***

In the top-down and bottom-up model, pattern recognition is a machine with sense data comes in from the bottom, and long term memory comes in from the top, and the output comes out of the side.



## Alternative Theories
- Perhaps we see vector lengths and angles?


# Sensation vs Perception
https://www.youtube.com/watch?v=rv4rZRkGv8Q

Sensation is not the same as perception. Take illusions for example:
- Hermann Grid
- Muller-Lyer arrows
- Ponzo railroad tie

**The Muller-Lyer illusion is more effective in western culture, but may support the idea that pattern recognition uses vectors and angles angles as atomic elements.**

***What is the role of projective geometry in these examples?*** It seems that the confusion occurs because we're context switching between a projective space and a non-projective space. In this way, the illusions are trick questions, and the illusory perception is actually true in a particular sense. ***We see the world as a projective space by default.***


**Sensation** is the product of our sensory information. **Perceptions** is the context of our experiences. We would say that perception arises from sensation.

We suffer from "looked but failed to see" errors, such as the parked police car that experienced drivers don't identify as stopped because they expect it to be moving based on its orientation. This shows us that experience has a huge effect on perception.



